{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Apresenta\u00e7\u00e3o","text":""},{"location":"#bem-vindo-a-documentacao-do-data-lake-da-saude-municipal-do-rio-de-janeiro","title":"Bem-vindo \u00e0 documenta\u00e7\u00e3o do Data Lake da Sa\u00fade Municipal do Rio de Janeiro","text":"<p>P\u00e1gina em Constru\u00e7\u00e3o</p> <p>Esta p\u00e1gina est\u00e1 atualmente em desenvolvimento. Agradecemos a sua paci\u00eancia enquanto trabalhamos para disponibilizar o conte\u00fado completo.</p> <p>Aqui, voc\u00ea encontrar\u00e1 um reposit\u00f3rio colaborativo de informa\u00e7\u00f5es para ajudar voc\u00ea a fazer o melhor uso de todos os recursos que podemos oferecer. Sinta-se \u00e0 vontade para navegar.</p> <p>Queremos convidar voc\u00ea para se juntar a n\u00f3s! Se tiver alguma d\u00favida, sugest\u00e3o ou identificou alguma uma inconsist\u00eancia, estamos aqui para ouvir e ajudar. Voc\u00ea pode entrar em contato conosco de duas maneiras super f\u00e1ceis:</p> <p>No Discord: Se voc\u00ea prefere um bate-papo mais direto, entre no nosso canal no Discord do CIT. </p> <p>Por e-mail: Mande suas perguntas ou ideias para nosso endere\u00e7o eletr\u00f4nico: dit-governanca@regulacaoriorj.com.br. Vamos ler com aten\u00e7\u00e3o e responder o mais r\u00e1pido poss\u00edvel.</p> <p>N\u00e3o hesite em nos procurar. Sua opini\u00e3o \u00e9 muito importante para n\u00f3s!</p> <p>At\u00e9 mais!</p> <p> Este espa\u00e7o \u00e9 mantido pelo Comit\u00ea de Tecnologia e Inova\u00e7\u00e3o da SMS com muito \u2764\ufe0f e \u2615\ufe0f. </p>"},{"location":"acessos/","title":"Acessos","text":""},{"location":"acessos/#como-solicitar-acesso-ao-ambiente-do-data-lake","title":"Como solicitar acesso ao ambiente do Data Lake","text":"<p>Para solicitar acesso ao ambiente do Data Lake ou ao Painel de Farm\u00e1cia Digital, siga os passos abaixo:</p> <ol> <li> <p>Solicite a inscri\u00e7\u00e3o ao seu gestor</p> <p>Entre em contato com o gestor da sua \u00e1rea e solicite que o mesmo preencha o formul\u00e1rio de acesso aos dados.</p> </li> <li> <p>Preencha o formul\u00e1rio de solicita\u00e7\u00e3o</p> <p>Complete o formul\u00e1rio fornecido pela equipe de governan\u00e7a de dados:</p> <ul> <li>para o Data Lake SMS Rio neste form (em breve);</li> <li>para o Painel de Farm\u00e1cia Digital neste form (em breve).</li> </ul> </li> <li> <p>Aguarde a aprova\u00e7\u00e3o</p> <p>Ap\u00f3s enviar sua solicita\u00e7\u00e3o, aguarde a aprova\u00e7\u00e3o da equipe de governan\u00e7a. Eles podem entrar em contato por email ou telefone para esclarecimentos adicionais.</p> </li> <li> <p>Receba as credenciais de acesso</p> <p>Com a aprova\u00e7\u00e3o, voc\u00ea receber\u00e1 suas credenciais de acesso e instru\u00e7\u00f5es sobre como acessar o Data Lake.</p> </li> </ol> <p>Caso tenha d\u00favidas durante o processo, n\u00e3o hesite em buscar suporte da equipe de governan\u00e7a do Data Lake da Sa\u00fade no e-mail dit-governanca@regulacaoriorj.com.br.</p>"},{"location":"governanca/","title":"Governan\u00e7a","text":""},{"location":"governanca/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O Data Lake da Sa\u00fade faz parte de uma iniciativa maior, capitaneada pela Prefeitura do Rio na figura do Escrit\u00f3rio de Dados, a fim de promover iniciativas transversais entre as Secretarias, visando \u00e0 melhoria da gest\u00e3o p\u00fablica e ao bem estar da popula\u00e7\u00e3o.</p> <p>Cada Secretaria possui o seu Date Lake, mas que s\u00e3o mantidos por infraestrutura comum no Google Cloud. Na pr\u00e1tica os dados das Secretarias s\u00e3o isoladas em ambientes exclusivos das mesmas, enquanto que a infraestrutura das camadas de orquestra\u00e7\u00e3o e processamento das cargas de trabalho \u00e9 compartilhada por toda a Prefeitura. Para mais detalhes ver Vis\u00e3o Geral da Infraestrutura.</p> <p></p>"},{"location":"governanca/#autonomia-sobre-os-dados","title":"Autonomia sobre os dados","text":"<p>Os dados de cada Secretaria s\u00e3o de total gest\u00e3o pr\u00f3pria. S\u00e3o elas que decidem o que, para quem e como compartilhar seus dados com outros atores p\u00fablicos ou privados.</p> <p>Por\u00e9m, elas precisam seguir alguns padr\u00f5es de organiza\u00e7\u00e3o da informa\u00e7\u00e3o para garantir a interoperabilidade dos dados entre todos os demais agentes da Prefeitura.</p>"},{"location":"governanca/#interoperabilidade-dos-dados-da-prefeitura","title":"Interoperabilidade dos dados da Prefeitura","text":"<p>A fim de garantir o a interoperabilidade dos dados da Prefeitura, o Escrit\u00f3rio de Dados tamb\u00e9m normatiza e audita como as informa\u00e7\u00f5es devem ser organizadas dentro do Data Lake:</p> <ul> <li>Padr\u00e3o de nomenclatura dos conjuntos de dados (datasets);</li> <li>Padr\u00e3o de nomenclatura das tabelas;</li> <li>Padr\u00e3o de nomenclatura dos campos;</li> </ul> <p>Para mais detalhes ver o Manual de Estilo da Prefeitura.</p>"},{"location":"governanca/#papeis-e-responsabilidades","title":"Pap\u00e9is e Responsabilidades","text":""},{"location":"governanca/#prefeitura-secretaria-de-saude","title":"Prefeitura &amp; Secretaria de Sa\u00fade","text":"<p>A SMS desenvolve e ser responsabiliza pelo conte\u00fado do Lake:</p> <ul> <li>Desenvolve e mant\u00e9m as extra\u00e7\u00f5es e transforma\u00e7\u00f5es dos dados (os pipelines de dados);</li> <li>Constr\u00f3i e mant\u00e9m os seus casos de uso (dashboards, reports, modelos de machine learning e outros produtos de dados);</li> <li>Controla os acessos para agentes internos e externos \u00e0 SMS;</li> <li>Conforma e se responsabiliza perante \u00e0 LGPD.</li> </ul> <p>Enquanto isso, o Escrit\u00f3rio de Dados, \u00e9 respons\u00e1vel por fornecer e manter a infraestrutura do Data Lake no n\u00edvel mais b\u00e1sico:</p> <ul> <li>Desenvolve sustenta os servi\u00e7os onde rodam as cargas de trabalho para extra\u00e7\u00e3o, carga e transforma\u00e7\u00e3o dos dados (cluster em Kubernets, servi\u00e7os de Containers, ...);</li> <li>Desenvolve e sustenta a camada de orquestra\u00e7\u00e3o dos pipelines (Prefect);</li> <li>Desenvolve e sustenta as esteiras de CI/CD para deploy autom\u00e1tico dos pipelines de dados;</li> <li>Regulamenta e garante a conformidade das informa\u00e7\u00f5es dentro dos Data Lakes (BigQuery) das Secretarias.</li> </ul>"},{"location":"governanca/#dentro-da-secretaria-de-saude","title":"Dentro da Secretaria de Sa\u00fade","text":"<p>Dentro da SMS, o Comit\u00ea de Inova\u00e7\u00e3o e Tecnologia (CIT) \u00e9 a figura que faz a interface com a Prefeitura. Suas responsabilidades s\u00e3o:</p> <ul> <li>Desenvolve os pipelines de dados da SMS</li> <li>Capacita outros atores dentro da SMS no desenvolvimento de novos pipelines de dados</li> <li>Monitora e garante a sa\u00fade (seguran\u00e7a, privacidade, acuracidade, disponibilidade e usabilidade) dos ativos de dados (tabelas do Data Lake; dashboards, reports, modelos de machine learning e outros produtos de dados conectados ao Data Lake)</li> <li>Gere os acessos ao Data Lake da SMS</li> <li>Garante a conformidade com os padr\u00f5es de Governan\u00e7a da Prefeitura</li> <li>Apoia o Escrit\u00f3rio de Dados no desenvolvimento e experimenta\u00e7\u00e3o de novas features e melhorias de infraestrutura e engenharia de dados para o Data Lake</li> </ul> <p>J\u00e1 os demais atores da SMS:</p> <ul> <li>Consomem as informa\u00e7\u00f5es do Data Lake e desenvolvem seus pr\u00f3prios reports, dashboards e modelos de machine learning.</li> <li>(Opcional) Desenvolvem novos pipelines de dados, contribuindo para expans\u00e3o deste projeto (para mais detalhes ver Contribuindo ao Projeto)</li> </ul>"},{"location":"guia-desenvolvedores/campos/","title":"Campos","text":""},{"location":"guia-desenvolvedores/campos/#quais-variaveis-manter-quais-adicionar-e-quais-remover","title":"Quais vari\u00e1veis manter, quais adicionar e quais remover","text":"<p>Mantemos nossas tabelas parcialmente\u00a0normalizadas, e temos regras para quais vari\u00e1veis incluirmos em produ\u00e7\u00e3o. Elas s\u00e3o:</p> <ul> <li> <p>Remover vari\u00e1veis de nomes de entidades que j\u00e1 est\u00e3o no Data Lake. Exemplo: retirar\u00a0<code>nome_estabelecimento</code>\u00a0da tabela que j\u00e1 inclui\u00a0<code>id_cnes</code>.</p> </li> <li> <p>Remover vari\u00e1veis j\u00e1 utilizadas como parti\u00e7\u00e3o. Exemplo: remover\u00a0<code>ano</code>\u00a0e\u00a0<code>data</code>\u00a0se a tabela \u00e9 particionada nessas duas dimens\u00f5es.</p> </li> <li> <p>Manter todas as chaves prim\u00e1rias que j\u00e1 vem com a tabela, mas (1) adicionar chaves estrangeiras relevantes (ex.\u00a0\u00a0<code>id_municipio</code>) e (2) retirar chaves  estrangeiras irrelevantes (e.g.\u00a0<code>regiao</code>).</p> </li> </ul>"},{"location":"guia-desenvolvedores/campos/#nomeacao-ordenamento-dos-campos","title":"Nomea\u00e7\u00e3o &amp; Ordenamento dos Campos","text":""},{"location":"guia-desenvolvedores/campos/#ordem-das-colunas","title":"Ordem das colunas","text":"<p>A ordem das colunas em tabelas \u00e9 padronizada para manter uma consist\u00eancia no Data Lake. Nossas regras s\u00e3o:</p> <ul> <li> <p>As chaves sempre s\u00e3o as primeiras colunas: primeiro a chave prim\u00e1ria, depois as chaves estrangeira em ordem descendente de abrang\u00eancia.</p> <ul> <li>Exemplo de ordem para uma tabela de atendimento:\u00a0<code>id_atendimento</code>,\u00a0<code>id_uf</code>,\u00a0<code>id_municipio</code>,\u00a0<code>id_cnes</code>,\u00a0<code>paciente_cpf</code>.</li> </ul> </li> <li> <p>Agrupar e ordenar colunas por import\u00e2ncia ou temas.</p> </li> </ul>"},{"location":"guia-desenvolvedores/campos/#nomeacao-das-colunas","title":"Nomea\u00e7\u00e3o das colunas","text":"<p>Os campos, de forma geral, deve seguir o seguinte Padr\u00e3o:</p> <p><code>[id_][&lt;entidade&gt;_][&lt;dimens\u00e3o&gt;][_&lt;unidade&gt;]</code></p>"},{"location":"guia-desenvolvedores/campos/#regras-gerais","title":"Regras gerais","text":"<p>Nomes de vari\u00e1veis devem respeitar algumas regras:</p> <ul> <li> <p>Usar ao m\u00e1ximo nomes j\u00e1 presentes no reposit\u00f3rio. Exemplos:\u00a0estabelecimento,\u00a0material,\u00a0profissional_saude,\u00a0episodio_assistencial</p> </li> <li> <p>Ser o mais intuitivo, claro e extenso poss\u00edvel.</p> </li> <li> <p>Ter todas letras min\u00fasculas (inclusive siglas), sem acentos, conectados por\u00a0_.</p> </li> <li> <p>N\u00e3o incluir conectores como\u00a0de,\u00a0da,\u00a0dos,\u00a0e,\u00a0a,\u00a0em, etc.</p> </li> </ul>"},{"location":"guia-desenvolvedores/campos/#id_","title":"<code>id_</code>","text":"<p>Como regra geral, as colunas de chave prim\u00e1ria e estrangeiras devem come\u00e7ar com o prefixo id  a fim de mantermos todas as colunas de chave agrupadas ao trabalhar com qualquer ferramenta de viz. Ex. <code>id_cnes</code>, <code>id_material</code>, <code>id_municipio</code>, <code>id_cid</code></p> <p>S\u00f3 devem ter o prefixo\u00a0id_\u00a0quando a vari\u00e1vel representar chaves prim\u00e1rias de entidades no Data Lake (que tem ou que eventualmente ter\u00e3o uma tabela no lake).</p> <p>Alguns casos especiais, quando o campo \u00e9 notoriamente conhecido como uma chave (ex. CPF ou CNS) o uso do prefixo pode ser descartado para fim de legibilidade.</p>"},{"location":"guia-desenvolvedores/campos/#entidade-prefixo-opcional","title":"<code>&lt;entidade&gt;</code> (Prefixo opcional)","text":"<p>Por modelarmos os dados no estilo de fatos e dimens\u00f5es, nossas tabelas n\u00e3o s\u00e3o rigorosamente normalizadas. Por isso, \u00e9 comum termos na mesma tabela colunas relativas \u00e0 diferentes entidades. Por isso adotamos o seguinte tratamento: adiciona*se o prefixo de entidade quando a entidade da coluna for diferente da entidade da tabela. Exemplos: </p> <ul> <li> <p>numa tabela sobre a entidade\u00a0estoque, uma coluna contendo a forma farmac\u00eautica do material seria declarada assim:\u00a0material_forma_farmaceutica.</p> </li> <li> <p>numa tabela sobre a entidade material, caracter\u00edsticas do material seriam descritas como forma_farmaceutica, posologia, grupo_terapeutico, etc.</p> </li> </ul> <p>No caso espec\u00edfico das tabelas da camada ouro, onde as tabelas est\u00e3o altamente desnormalizados, recomenda-se que todas as colunas contenham o prefixo da entidade \u00e0 qual pertecem. Essa pr\u00e1tica facilita a busca das informa\u00e7\u00f5es nas ferramentas de BI, visto que elas, geralmente, ficam ordenadas alfabeticamente.</p>"},{"location":"guia-desenvolvedores/campos/#dimensao-obrigatorio","title":"<code>&lt;dimens\u00e3o&gt;</code> (Obrigat\u00f3rio)","text":"<p>Nomear a dimens\u00e3o \u00e9 algo menos estruturado e, por isso, requer bom senso. Neste quesito a \u00fanica restri\u00e7\u00e3o \u00e9 respeitar as regras gerais listadas no in\u00edcio desta sess\u00e3o.</p>"},{"location":"guia-desenvolvedores/campos/#_unidade-sufixo-opcional","title":"<code>&lt;_unidade&gt;</code> (Sufixo opcional)","text":"<p>Recomenda*se a utiliza\u00e7\u00e3o de sufixos para declara\u00e7\u00e3o da unidade a fim de aumentar a legibilidade do campo. Lista de\u00a0unidades permitidas:</p> <ul> <li><code>_nome</code>,</li> <li><code>_data</code></li> <li><code>_datahora</code>,</li> <li><code>_valor</code>,</li> <li><code>_quantidade</code>,</li> <li><code>_proporcao</code>\u00a0(vari\u00e1veis de porcentagem 0*100%),</li> <li><code>_taxa</code>,</li> <li><code>_razao</code>,</li> <li><code>_indicador</code>\u00a0(vari\u00e1veis do tipo booleano),</li> <li><code>_tipo</code>,</li> <li><code>_sigla</code></li> </ul>"},{"location":"guia-desenvolvedores/campos/#representacao-dos-valores","title":"Representa\u00e7\u00e3o dos Valores","text":""},{"location":"guia-desenvolvedores/campos/#limpando-strings","title":"Limpando STRINGs","text":"<p>A limpeza dos campos vai variar conforme o prop\u00f3sito de cada tabela nas camadas Gold, sendo convencionado apenas para os tiers Bronze e Prata os seguintes pontos, do mais abrangente para o mais espec\u00edfico:</p> <ul> <li> <p>Todo campo string n\u00e3o deve iniciar com espa\u00e7os ou tab (\\n), esses devem ser padronizados usando a fun\u00e7\u00e3o <code>TRIM()</code>.</p> </li> <li> <p>Campos de strings nullables: dever\u00e3o ser padronizadas utilizando a macro <code>process_null</code> que garante que strings como <code>\"NaN\"</code>, <code>\"None\"</code> e <code>\"\"</code> sejam transformadas em em <code>null</code>, segundo o formato do BigQuery.</p> </li> <li> <p>Campos num\u00e9ricos: dever\u00e3o conter limpeza de caracteres n\u00e3o num\u00e9ricos segundo a macro <code>clean_numeric_string</code>.</p> </li> <li> <p>Campos categ\u00f3ricas: dever\u00e3o ser padronizadas com inicial mai\u00fascula e resto min\u00fasculo, sem acentos seguindo macro <code>remove_accents_upper</code> e <code>capitalize_first_letter</code> nessa ordem.</p> </li> <li> <p>Campos de nome e endere\u00e7o (ex: nome de estabelecimento, nome pr\u00f3prio e logradouro) devem ser padronizadas com letras ma\u00edusculas no inicio de cada nome e preposi\u00e7\u00f5es em min\u00fascula, sem acentos ou s\u00edmbolos <code>-</code> . Utiliza-se as macros <code>remove_accents_upper</code> seguida de <code>proper_estabelecimento</code> ou <code>proper_br</code>. </p> </li> <li> <p>Em campos de texto livre, mantemos igual aos dados originais.</p> </li> <li> <p>Analisar casos de s\u00edmbolos especificos que quando retirados temos perda sem\u00e2ntica. Ex: \"AV JULIO DE AMORIM PEREIRA  S/N\" \u2192 \"AV JULIO DE AMORIM PEREIRA  SN\" </p> </li> </ul>"},{"location":"guia-desenvolvedores/campos/#formatos-de-valores","title":"Formatos de valores","text":"<ul> <li>Decimal: formato americano, i.e. sempre\u00a0<code>.</code>\u00a0(ponto) ao inv\u00e9s de\u00a0<code>,</code>\u00a0(v\u00edrgula).</li> <li>Data:\u00a0<code>YYYY-MM-DD</code></li> <li>Hor\u00e1rio (24h):\u00a0<code>HH:MM:SS</code></li> <li>Datetime (ISO-8601):\u00a0<code>YYYY-MM-DDTHH:MM:SS.sssZ</code></li> <li>Valor nulo:\u00a0<code>\"\"</code>\u00a0(csv, Stata),\u00a0<code>NULL</code>\u00a0(Python),\u00a0<code>NA</code>\u00a0(R) ou <code>.</code></li> <li>Propor\u00e7\u00e3o/porcentagem: entre 0*100</li> <li>Booleano: <code>false</code>/<code>true</code></li> <li>Sexo: Masculino/Feminino</li> </ul>"},{"location":"guia-desenvolvedores/campos/#colunas-de-particionamento-da-tabela","title":"Colunas de Particionamento da Tabela","text":"<p>Uma tabela particionada \u00e9 uma tabela especial dividida em segmentos, chamados de parti\u00e7\u00f5es, que facilitam o gerenciamento e a consulta de seus dados. Ao dividir uma grande tabela em parti\u00e7\u00f5es menores, voc\u00ea pode melhorar o desempenho da consulta e pode controlar os custos reduzindo o n\u00famero de bytes lidos por uma consulta. Por isso, sempre recomendamos que tabelas grandes sejam particionadas. Leia mais  a respeito na\u00a0documenta\u00e7\u00e3o da Google Cloud.</p> <p>Em geral, o particionamento \u00e9 feito sobre o valors de uma data criando-se tr\u00eas colunas novas cujos nomes s\u00e3o dados por:\u00a0<code>ano_particao</code>,\u00a0<code>mes_particao</code>,<code>data_particao</code>\u00a0e que possuem os respectivos formatos 'YYYY', 'MM', 'YYYY-MM-DD'. </p>"},{"location":"guia-desenvolvedores/contribuindo-projeto/","title":"Contribuindo para o projeto","text":"<p>Voc\u00ea deseja um dataset que n\u00e3o est\u00e1 no Data Lake? Voc\u00ea quer plugar seus Dashboards e Reports numa estrutura mais robusta contra falhas?</p> <p>N\u00f3s do CIT ajudamos seu time a dar os primeiros passos para ganhar mais autonomia dentro do Data Lake. Se seu time sabe Python &amp; Git ou SQL &amp; Git, n\u00f3s apoiamos no desenvolvimento dos primeiros pipelines para trazer os dados para dentro do Lake ou nos pipelines que montam as tabelas dentro do BigQuery e que alimentar\u00e3o seus reports, dashboards ou modelos de machine learning.</p> <p>Importante</p> <p>Ao desenvolver qualquer pipeline para o Data Lake, seu time passa a ser o respons\u00e1vel pela sua manuten\u00e7\u00e3o. Em caso de quebra e n\u00e3o repara\u00e7\u00e3o, ele ser\u00e1 exclu\u00eddo do ambiente.</p> <p></p>"},{"location":"guia-desenvolvedores/infraestrutura/","title":"Vis\u00e3o Geral da Infraestrutura","text":"<p>O Data Lake da Sa\u00fade \u00e9 composto por v\u00e1rias ferramentas e tecnologias que trabalham juntas para coletar, armazenar, gerenciar e analisar esses dados. Cada componente tem um papel espec\u00edfico e, quando combinados, eles criam um ecossistema poderoso para o tratamento de grandes volumes de informa\u00e7\u00f5es. Vamos explorar os principais componentes que formam um Data Lake eficiente:</p> <ol> <li> <p>Orquestra\u00e7\u00e3o com Prefect: Essencial para garantir que as tarefas sejam executadas de forma ordenada e eficaz. Ele  \u00e9 a espinha dorsal da automa\u00e7\u00e3o de fluxos de trabalho, assegurando que os processos de ELT (Extract, Load, Transform) sejam executados de maneira confi\u00e1vel e escal\u00e1vel.</p> </li> <li> <p>Data Warehouse com BigQuery: O lugar onde os dados s\u00e3o armazenados de maneira estruturada e prontos para an\u00e1lise. Nele voc\u00ea pode realizar consultas SQL de alta velocidade e armazenar dados transformados para an\u00e1lises mais recorrentes.</p> </li> <li> <p>Constru\u00e7\u00e3o e Monitoramento com DBT: Ferramenta  respons\u00e1vel pela transforma\u00e7\u00e3o (T do ELT) dos dados dentro do Data Warehouse e pelo monitoramento dos mesmos. Ao trazer o conceito de versionamento de c\u00f3digo e testes automatizados ao processo de transforma\u00e7\u00e3o dos dados, proporciona uma camada adicional de governan\u00e7a e qualidade aos dados no Data Warehouse.</p> </li> <li> <p>Notifica\u00e7\u00f5es de Falhas via Discord: Sistema de alerta que notifica a equipe respons\u00e1vel caso ocorram problemas nos processos de dados. Ele oferece uma comunica\u00e7\u00e3o imediata sobre quaisquer interrup\u00e7\u00f5es ou falhas, permitindo uma r\u00e1pida resposta e resolu\u00e7\u00e3o.</p> </li> <li> <p>An\u00e1lise de Dados com Python, R, Power BI e Looker: Conjunto de ferramentas que permitem aos usu\u00e1rios acessar, analisar e visualizar os dados armazenados no Data Lake.</p> </li> </ol> <p>Cada um desses componentes desempenha um papel vital na constru\u00e7\u00e3o para que o Data Lake seja robusto e funcional. Juntos, eles oferecem uma infraestrutura completa para que a SMS possa aproveitar ao m\u00e1ximo seus dados</p> <p></p>"},{"location":"guia-uso/consultas-diretas/","title":"Consultas diretas no Data Lake","text":"<p>Nota</p> <p>O BigQuery \u00e9 a ferramenta padr\u00e3o para acessar os dados no Data Lake. Seu meio de acesso \u00e9 atrav\u00e9s de uma interface web onde \u00e9 poss\u00edvel realizar consultas SQL. A partir dele \u00e9 poss\u00edvel extrair as informa\u00e7\u00f5es para outros meios comumente utilizados como planilhas, arquivos de texto como csv, ou at\u00e9 para o Google Drive.</p>"},{"location":"guia-uso/consultas-diretas/#acessando-o-bigquery","title":"Acessando o BigQuery","text":"<p>Para acessar o ambiente basta acessar este link e acessar com o usu\u00e1rio e senha que foi habilitado quando seu acesso foi solicitado.  Ao acessar o link voc\u00ea ver\u00e1 esta tela:</p> <p></p> <p>Neste bot\u00e3o voc\u00ea poder\u00e1 alternar entre os ambientes de <code>rj-sms</code> (Produ\u00e7\u00e3o) e <code>rj-sms-sandbox</code> (Sandbox), confira se esta no ambiente correto antes de iniciar.</p> <p></p> <p>A tela inicial do BigQuery Studio oferece um ambiente centralizado para gerenciar e executar consultas e visualizar dados.</p>"},{"location":"guia-uso/consultas-diretas/#painel-explorer","title":"Painel Explorer","text":"<p>Localizado \u00e0 esquerda da tela, o painel de Explorer  permite acessar diferentes recursos, como consultas, projetos, conjuntos de dados. Ele oferece uma maneira conveniente de alternar entre as diferentes funcionalidades do BigQuery.</p>"},{"location":"guia-uso/consultas-diretas/#barra-de-ferramentas","title":"Barra de Ferramentas","text":"<p>A barra de ferramentas na parte superior da tela fornece acesso r\u00e1pido a recursos essenciais, como a execu\u00e7\u00e3o de consultas, a cria\u00e7\u00e3o de visualiza\u00e7\u00f5es e o gerenciamento de consultas salvas.</p>"},{"location":"guia-uso/consultas-diretas/#guia-consultar","title":"Guia Consultar","text":"<p>A guia \"Consultar\" \u00e9 onde voc\u00ea pode escrever consultas SQL para analisar  seus dados. Ela oferece recursos avan\u00e7ados de edi\u00e7\u00e3o, realce de sintaxe e autocompletar, para facilitar a cria\u00e7\u00e3o de consultas complexas.</p>"},{"location":"guia-uso/consultas-diretas/#painel-de-visualizacao","title":"Painel de Visualiza\u00e7\u00e3o","text":"<p>Logo abaixo da guia de consulta, o painel de visualiza\u00e7\u00e3o exibe os resultados das consultas em formato de tabela, facilitando a an\u00e1lise e a interpreta\u00e7\u00e3o dos dados.</p> <p>Esses elementos combinados oferecem uma experi\u00eancia completa para consultar, visualizar e gerenciar dados diretamente no BigQuery Studio, proporcionando um ambiente poderoso para an\u00e1lise e tomada de decis\u00f5es baseadas em dados. </p>"},{"location":"guia-uso/consultas-diretas/#criando-uma-consulta","title":"Criando uma Consulta","text":"<p>No Console do BigQuery, clique em \"Nova consulta\" para abrir o editor de consultas.</p> <p>Escreva sua consulta SQL no editor. Por exemplo:</p> <p>Observa\u00e7\u00e3o</p> <p>Incentivamos o uso de consultas que utilizem filtro pelas colunas de parti\u00e7\u00e3o da tabela. Esta pr\u00e1tica reduz o tempo e o custo da consulta.</p> <pre><code>SELECT\n    *\nFROM `seu_projeto.seu_dataset.tabela`\nWHERE coluna_particao &gt;= condicao\n</code></pre> <p></p>"},{"location":"guia-uso/consultas-diretas/#executando-a-consulta","title":"Executando a Consulta","text":"<p>Depois de escrever sua consulta, clique em \"Executar\" ou pressione Ctrl+Enter para execut\u00e1-la. Os resultados da consulta ser\u00e3o exibidos na parte inferior do console.</p>"},{"location":"guia-uso/consultas-diretas/#exportando-dados-no-bigquery","title":"Exportando Dados no BigQuery","text":"<p>Com os resultado da consulta em tela, podemos salvar os dados  localmente nos formatos  CSV (Comma-Separated Values) ou JSON (JavaScript Object Notation) . Uma op\u00e7\u00e3o tamb\u00e9m \u00e9 levar esses dados para o GCS, nos formatos CSV, JSONL, Planilha do Google ou tabela do BigQuery, como no exemplo a seguir.</p> <p>Usando o bot\u00e3o  SALVAR RESULTADOS  temos as seguintes op\u00e7\u00f5es abaixo.</p> <p></p>"},{"location":"guia-uso/organizacao-dados/","title":"Organiza\u00e7\u00e3o dos Dados no Data Lake","text":""},{"location":"guia-uso/organizacao-dados/#afinal-onde-estao-os-dados","title":"Afinal, onde est\u00e3o os dados?","text":"<p>O BigQuery \u00e9 a ferramenta onde est\u00e3o guardados nossos dados e que tamb\u00e9m utilizamos para fazer as consultas SQL. Ele \u00e9 um servi\u00e7o de Data Warehouse totalmente gerenciado e altamente escal\u00e1vel oferecido pelo Google Cloud Platform. Ele permite armazenar, consultar e analisar grandes conjuntos de dados de maneira r\u00e1pida e eficiente.</p>"},{"location":"guia-uso/organizacao-dados/#organizacao-dos-dados-em-camadas","title":"Organiza\u00e7\u00e3o dos dados em Camadas","text":"<p>Os dados em nosso BigQuery s\u00e3o organizado seguindo o padr\u00e3o de design de dados conhecido como arquitetura medalh\u00e3o. Este padr\u00e3o consiste em organizar logicamente os dados em um Data Lake, com o objetivo de melhorar incremental e progressivamente a estrutura e qualidade dos dados \u00e0 medida que eles fluem por cada camada da arquitetura (isto \u00e9, entre as tabelas da camada Bronze \u21d2 Prata \u21d2 Ouro):</p> <ol> <li>Bronze ou Dados Brutos: \u00e9 onde depositamos todos os dados dos sistemas de origem externos. As estruturas de tabela nesta camada correspondem \u00e0s estruturas de tabela do sistema de origem \"como est\u00e3o\", juntamente com quaisquer colunas de metadados adicionais que capturem a data/hora de carga, o ID do processo, etc.</li> </ol> <p></p> <ol> <li>Prata ou Dados Mestres: nesta camada os dados da camada Bronze s\u00e3o correspondidos, unificados, padronizados e limpos (\"o suficiente\") para que a camada Prata possa fornecer uma \"vis\u00e3o Institucional\" de todas as suas principais entidades de sa\u00fade, conceitos e transa\u00e7\u00f5es (por exemplo, pacientes mestres, unidades de sa\u00fade mestres, estoque de insumos e medicamentos unificados, registros de vacina\u00e7\u00e3o n\u00e3o duplicados,  ...). Ela serve como uma fonte para os desenvolvedores criarem projetos e an\u00e1lises adicionais para resolver problemas na \u00e1rea da sa\u00fade.</li> </ol> <p></p> <ol> <li>Ouro ou Casos de Uso: Os dados na camada Ouro geralmente s\u00e3o organizados em bancos de dados \"espec\u00edficos do projeto\", prontos para o consumo. A camada Ouro \u00e9 para relat\u00f3rios ou dashboards, e utiliza modelos de dados mais desnormalizados (tabel\u00f5es) e otimizados para leitura, com menos jun\u00e7\u00f5es (joins).</li> </ol> <p>Dentro do Big Query, estas camadas s\u00e3o facilmente identificados pelos prefixos associados aos conjuntos de tabelas (datasets):</p> <p></p>"},{"location":"guia-uso/outras-formas/","title":"Acessando por outras plataformas","text":""},{"location":"guia-uso/outras-formas/#sumario","title":"Sum\u00e1rio","text":"<p>Nesta se\u00e7\u00e3o voc\u00ea aprender\u00e1 a acessar o Data Lake atrav\u00e9s das seguintes feramentas:</p> <ul> <li>Python</li> <li>R</li> <li>Google Colab</li> <li>Looker</li> </ul>"},{"location":"guia-uso/outras-formas/#python","title":"Python","text":"<p>Importante</p> <p>Para conectar o Python voc\u00ea precisar\u00e1 de uma conta de servi\u00e7o, este \u00e9 um acesso diferente daquele que \u00e9 dado por padr\u00e3o ao Data Lake. </p> <code>credential.json</code> <p>Este acesso tem a forma de um arquivo <code>.json</code> com o conte\u00fado similar a este: <pre><code>{\n    \"type\": \"service_account\",\n    \"project_id\": \"rj-sms\",\n    \"private_key_id\": \"XXXXXX\",\n    \"private_key\": \"-----BEGIN PRIVATE KEY------\n    [CHAVE] ----END PRIVATE KEY-----\\n\",\n    \"client_email\": \"email@dominio.com\",\n    \"client_id\": \"0000000\",\n    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n    \"client_x509_cert_url\": \"\"\n}\n</code></pre></p> <p>Caso n\u00e3o tenha, solicite sua conta de servi\u00e7o.</p>"},{"location":"guia-uso/outras-formas/#passo-a-passo-para-conectar","title":"Passo a passo para conectar","text":""},{"location":"guia-uso/outras-formas/#1-instale-a-biblioteca-do-google-cloud-para-o-python","title":"1. Instale a biblioteca do Google Cloud para o Python","text":"<pre><code>pip install google-cloud-bigquery\n</code></pre>"},{"location":"guia-uso/outras-formas/#2-autentique-no-google-cloud","title":"2. Autentique no Google Cloud","text":"<p>Para autenticar no Google Cloud, a biblioteca busca uma vari\u00e1vel de ambiente chamada <code>GOOGLE_APPLICATION_CREDENTIALS</code> que cont\u00e9m o caminho o json da conta de servi\u00e7o.</p> <p>A forma mais simples de injetar as credenciais no ambiente \u00e9 atrav\u00e9s deste comando no terminal:</p> <p><pre><code>export GOOGLE_APPLICATION_CREDENTIALS=\"/caminho/para/seu/arquivo-de-credenciais.json\"\n</code></pre> Caso queria fazer direto via python, a inje\u00e7\u00e3o das credenciais pode ser feita desta forma:</p> <pre><code>import os\n\ncredentials_path = \"/path/to/your/gcp/credentials.json\"\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n</code></pre>"},{"location":"guia-uso/outras-formas/#3-importe-a-biblioteca-e-crie-um-cliente-do-bigquery","title":"3. Importe a biblioteca e crie um cliente do BigQuery","text":"<p>No seu script Python, importe a classe bigquery do m\u00f3dulo google.cloud.bigquery. Em seguida, crie uma inst\u00e2ncia de Client para se conectar ao BigQuery:</p> <pre><code>from google.cloud import bigquery\n\n# Crie um cliente do BigQuery\nclient = bigquery.Client()\n</code></pre>"},{"location":"guia-uso/outras-formas/#4-execute-consultas-sql","title":"4. Execute consultas SQL","text":"<pre><code>import pandas as pd\nfrom google.cloud import bigquery\n\nclient = bigquery.Client()\n\n# Escreva sua consulta SQL\nquery = \"\"\"\nSELECT *\nFROM `seu-projeto.seu_dataset.sua_tabela`\n\"\"\"\n\n# Execute a consulta\nquery_job = client.query(query)\n\n# Carregue a consulta em um dataframe\ndf = query_job.to_dataframe()\n</code></pre>"},{"location":"guia-uso/outras-formas/#r","title":"R","text":""},{"location":"guia-uso/outras-formas/#passo-a-passo-para-conectar_1","title":"Passo a passo para conectar","text":""},{"location":"guia-uso/outras-formas/#1-instale-a-biblioteca-do-google-cloud-para-o-r","title":"1. Instale a biblioteca do Google Cloud para o R","text":"<pre><code>install.packages(\"bigrquery\")\n</code></pre>"},{"location":"guia-uso/outras-formas/#2-autentique-no-google-cloud_1","title":"2. Autentique no Google Cloud","text":"<p>Para autenticar no Google Cloud, basta chamar uma conex\u00e3o pela primeira vez que voc\u00ea ser\u00e1 direcionado para autenticar pelo navegador: </p> <pre><code>library(bigrquery)\nlibrary(DBI)\n\n# Crie uma conex\u00e3o para se conectar ao BigQuery\ncon &lt;- dbConnect(\n  bigrquery::bigquery(),\n  project = \"rj-sms\"\n)\n</code></pre> <p>Ainda nesta primeira vez que chamar a conex\u00e3o, \u00e9 poss\u00edvel que o R pe\u00e7a para instalar uma biblioteca adicional, proceda com a instala\u00e7\u00e3o para que a autentica\u00e7\u00e3o funcione. </p> <p>Uma vez instalado, voc\u00ea ser\u00e1 redirecionado para o navegador onde permitir\u00e1 a leitura das suas credenciais do Google:</p> <p></p> <p>Selecione o usu\u00e1rio que tem acesso ao BigQuery, permita o acesso e feche a aba do navegador.</p>"},{"location":"guia-uso/outras-formas/#3-execute-consultas-sql","title":"3. Execute consultas SQL","text":"<p>Com o cliente BigQuery configurado, voc\u00ea pode usar m\u00e9todos como query  para enviar consultas SQL e obter resultados:</p> <pre><code># Escreva sua consulta SQL\nquery &lt;- \"\nSELECT *\nFROM `seu-projeto.seu_dataset.sua_tabela`\n\"\n\n# Execute a consulta\nresult &lt;- dbGetQuery(con, query)\n</code></pre>"},{"location":"guia-uso/outras-formas/#google-colab","title":"Google Colab","text":""},{"location":"guia-uso/outras-formas/#passo-a-passo-para-conectar_2","title":"Passo a passo para conectar","text":""},{"location":"guia-uso/outras-formas/#1-crie-um-novo-notebook-e-importe-as-bibliotecas-necessarias","title":"1. Crie um novo notebook e importe as bibliotecas necess\u00e1rias","text":"<p>Ap\u00f3s selecionar um Novo Notebook, importe as bibliotecas necess\u00e1rias para se conectar ao BigQuery. </p> <pre><code>from google.cloud import bigquery\nfrom google.colab import auth\nauth.authenticate_user()\n</code></pre> <p>Nota</p> <p><code>auth.authenticate_user()</code> ir\u00e1 abrir um pop-out para logar com a sua conta Google com acesso ao BigQuery.</p>"},{"location":"guia-uso/outras-formas/#2-execute-consultas-sql","title":"2. Execute consultas SQL","text":"<pre><code>query = \"\"\"\nSELECT *\nFROM `projeto.dataset.tabela`\nLIMIT 10\n\"\"\"\n\ndf = client.query(query).to_dataframe()\ndf.head()\n</code></pre>"},{"location":"guia-uso/outras-formas/#looker","title":"Looker","text":"<p>Dica</p> <p>O Looker e o BigQuery, utilizam a mesma autentica\u00e7\u00e3o. Caso voc\u00ea j\u00e1 tenha acesso ao BigQuery da SMS, basta acessar o link da ferramenta e seguir os passo abaixo para conectar seus dados.</p>"},{"location":"guia-uso/outras-formas/#passo-a-passo-para-conectar_3","title":"Passo a passo para conectar","text":""},{"location":"guia-uso/outras-formas/#1-configure-uma-conexao-no-looker","title":"1. Configure uma conex\u00e3o no Looker","text":"<p>Fa\u00e7a login no Looker com as mesmas credenciais do BigQuery  Na tela inicial, comece um novo modelo, clicando em Relat\u00f3rio em branco. </p> <p></p>"},{"location":"guia-uso/outras-formas/#2-no-menu-de-adicionar-dados-ao-relatorio-navegue-ate-adicionar-dados-e-selecione-o-google-conector-bigquery","title":"2. No menu de Adicionar dados ao relat\u00f3rio , navegue at\u00e9 \"Adicionar Dados\" e selecione o Google conector \"BigQuery\".","text":""},{"location":"guia-uso/outras-formas/#3-selecione-o-projeto","title":"3. Selecione o projeto","text":""},{"location":"guia-uso/outras-formas/#4-preencha-o-campo-inserir-o-id-do-projeto-manualmente-com-o-ambiente-no-qual-foi-solicitado-o-acesso-para-o-ambiente-produtivo-do-lake-o-projeto-e-rj-sms","title":"4. Preencha o campo \"Inserir o ID do projeto manualmente\", com o ambiente no qual foi solicitado o acesso. Para o ambiente produtivo do Lake, o projeto \u00e9 <code>rj-sms</code>.","text":""},{"location":"guia-uso/outras-formas/#5-em-seguida-escolha-o-conjunto-de-dados-para-inserir-ao-seu-relatorio","title":"5. Em seguida escolha o conjunto de dados para inserir ao seu relat\u00f3rio.","text":""},{"location":"guia-uso/sandbox/","title":"Ambiente Sandbox","text":""},{"location":"guia-uso/sandbox/#o-que-e-o-sandbox","title":"O que \u00e9 o Sandbox?","text":"<p>O Sandbox, ou Caixa de Areia  , \u00e9 uma \u00e1rea dentro do nosso BigQuery onde os usu\u00e1rios podem criar novos conjuntos de dados, sejam tabelas materializadas ou views, a partir de upload de arquivos, conex\u00e3o com com planilhas do Google Sheets, por instru\u00e7\u00e3o SQL ou qualquer outra linguagem de programa\u00e7\u00e3o a partir de bibliotecas espec\u00edficas. Nele tamb\u00e9m \u00e9 poss\u00edvel consultar e mesclar os dados que est\u00e3o em produ\u00e7\u00e3o sem o risco de qualquer tipo consequ\u00eancia nesse ambiente.</p> <p>O ambiente do Sandbox dentro do BigQuery \u00e9 destinado aos atores internos e externos \u00e0 Secretaria de Sa\u00fade para testarem com autonomia e agilidade. \u00c9 um espa\u00e7o seguro onde os analistas e cientistas de dados podem experimentar com os dados, testar novas ideias ou modelos sem o risco de afetar os dados principais ou os sistemas de produ\u00e7\u00e3o.</p> <p>Pense nisso como um laborat\u00f3rio onde voc\u00ea pode trabalhar com c\u00f3pias dos dados reais ou com dados sint\u00e9ticos para desenvolver novos algoritmos, relat\u00f3rios ou visualiza\u00e7\u00f5es.</p> <p>Aqui est\u00e3o alguns pontos importantes sobre o Sandbox no Data Lake:</p> <ol> <li>Isolamento: O Sandbox mant\u00e9m suas experi\u00eancias separadas do ambiente principal, garantindo que o trabalho regular n\u00e3o seja interrompido.</li> <li>Liberdade para inovar: Como \u00e9 um ambiente controlado, h\u00e1 mais liberdade para tentar coisas novas sem medo de cometer erros que possam ter grandes consequ\u00eancias.</li> <li>Desenvolvimento \u00e1gil: Ajuda a acelerar o desenvolvimento de projetos de dados, pois as mudan\u00e7as podem ser feitas e testadas rapidamente.</li> <li>Seguran\u00e7a dos dados: Protege os dados sens\u00edveis ou cr\u00edticos ao permitir que os usu\u00e1rios trabalhem com amostras, vers\u00f5es anonimizadas ou sint\u00e9ticas dos dados.</li> <li>Aprendizado e crescimento: \u00c9 um \u00f3timo lugar para os membros da equipe melhorarem suas habilidades, pois eles podem aprender fazendo, sem press\u00e3o.</li> </ol> <p>Importante</p> <p>O Sandbox n\u00e3o \u00e9 ambiente produtivo!</p> <p>Por um lado isso \u00e9 \u00f3timo, voc\u00eas t\u00eam total autonomia para criar, modificar e destruir tudo dentro dos seus ambiente. Por outro lado, ele n\u00e3o possui as mesma prote\u00e7\u00f5es que o ambiente produtivo possui: Pol\u00edtica de Backup: inexistente neste ambiente.  Voc\u00ea \u00e9 respons\u00e1vel por garantir o backup das informa\u00e7\u00f5es que criou. Teste, monitoramento e notifica\u00e7\u00f5es autom\u00e1ticos: inexistente neste ambiente.  Caso ocorra alguma indisponibilidade ou erro nos dados, total ou parcial, n\u00e3o haver\u00e1 qualquer mecanismo de preven\u00e7\u00e3o ou alerta.</p> <p>Pelos motivos listados acima, n\u00e3o recomendamos que utilizem o Sandbox como ambiente produtivo. Isto \u00e9, n\u00e3o conectem no Sandbox seus reports, dashboards ou modelos de machine learning que ir\u00e3o ser consumidos pelos usu\u00e1rios finais. Pipelines de dados s\u00e3o vivos, inevitavelmente quebrar\u00e3o e descobrir pelo usu\u00e1rio \u00e9 uma experi\u00eancia bem ruim \ud83e\udee0. Quando acreditarem que prot\u00f3tipo atingiu o n\u00edvel de maturidade para subir para produ\u00e7\u00e3o. Falem conosco, iremos te ajudar a subir para o ambiente produtivo \ud83e\udd20. </p>"},{"location":"guia-uso/sandbox/#como-acessar-o-sandbox","title":"Como acessar o Sandbox?","text":"<p>Voc\u00ea pode acessar o Sandbox a partir deste link ou direto dentro BigQuery alterando o projeto que est\u00e1 conectado:</p> <ol> <li>Clicar no nome do projeto para abrir a lista de op\u00e7\u00f5es dispon\u00edveis</li> </ol> <p></p> <ol> <li>Selecionar o projeto do Sandbox:</li> </ol> <p></p> <p>Uma vez no Sandbox, voc\u00ea ver\u00e1 um conjunto de dados (dataset) com o respectivo nome da sua \u00e1rea:</p> <p></p> <p>Dentro do conjunto de dados da sua \u00e1rea, voc\u00ea tem total autonomia para criar, modificar e deletar tabelas e views.</p> <p>Caso voc\u00ea n\u00e3o esteja vendo o ambiente produtivo (projeto rj-sms):</p> <p>Para adicion\u00e1-lo basta seguir as orienta\u00e7\u00f5es em Primeiros Passos do link abaixo., substituindo o projeto basedosdados por rj-sms:</p> <p></p>"},{"location":"guia-uso/sandbox/#operacoes-basicas","title":"Opera\u00e7\u00f5es B\u00e1sicas","text":""},{"location":"guia-uso/sandbox/#upload-de-dados","title":"Upload de dados","text":""},{"location":"guia-uso/sandbox/#1-arquivos-de-texto","title":"1. Arquivos de Texto","text":"<p>Importante</p> <p>Para carregar com sucesso um arquivo no BigQuery \u00e9 necess\u00e1rio respeitar as limita\u00e7\u00f5es da ferramenta para cada tipo de arquivo. Ex:</p> <ul> <li>caracteres permitidos nos nomes das colunas</li> <li>como datas devem ser representadas</li> <li>qual caracter deve ser utilizado para definir o in\u00edcio das casas decimais</li> </ul> <p>Para conhecer sobre essas limita\u00e7\u00f5es acessar a documenta\u00e7\u00e3o, no menu da esquerda selecionar o tipo de arquivo que deseja carregar e buscar pela sess\u00e3o Limita\u00e7\u00f5es.</p>"},{"location":"sobre/sobre/","title":"Sobre","text":""},{"location":"sobre/sobre/#comite-de-inovacoes-e-tecnologia","title":"Comit\u00ea de Inova\u00e7\u00f5es e Tecnologia","text":"<p>O Comit\u00ea de Inova\u00e7\u00f5es e Tecnologia (S/CIT) \u00e9 a equipe respons\u00e1vel pela infraestrutura do Data Lake da SMS Rio. Al\u00e9m disso, incentivamos e viabilizamos o uso de dados integrados entre as equipes e subsecretarias da SMS preservando as boas pr\u00e1ticas de seguran\u00e7a da informa\u00e7\u00e3o.</p>"},{"location":"sobre/sobre/#competencias","title":"Compet\u00eancias","text":"<ul> <li> <p>Implementar e gerenciar as a\u00e7\u00f5es de dados alinhados com a inova\u00e7\u00e3o e tecnologia em sa\u00fade, em conformidade com as diretrizes do Sistema \u00danico de Sa\u00fade - SUS e com as prioridades estrat\u00e9gicas do munic\u00edpio do Rio de Janeiro;</p> </li> <li> <p>gerenciar as a\u00e7\u00f5es de integra\u00e7\u00e3o, interoperabilidade e seguran\u00e7a dos dados para subsidiar a tomada de decis\u00e3o, o monitoramento e a avalia\u00e7\u00e3o das a\u00e7\u00f5es e servi\u00e7os de sa\u00fade, com vistas \u00e0 consolida\u00e7\u00e3o de pol\u00edticas p\u00fablicas baseadas em evid\u00eancias;</p> </li> <li> <p>monitorar o reposit\u00f3rio de dados centralizados da Secretaria Municipal de Sa\u00fade, com a fun\u00e7\u00e3o de centraliza\u00e7\u00e3o, integra\u00e7\u00e3o, cataloga\u00e7\u00e3o e compartilhamento de dados;</p> </li> <li> <p>prestar apoio t\u00e9cnico \u00e0s unidades e setores da SMS na incorpora\u00e7\u00e3o e uso adequado de tecnologia da informa\u00e7\u00e3o, intelig\u00eancia artificial e solu\u00e7\u00f5es de armazenamento e prote\u00e7\u00e3o de dados;</p> </li> <li> <p>promover:</p> <ul> <li> <p>a pesquisa, o desenvolvimento e a ado\u00e7\u00e3o de solu\u00e7\u00f5es inovadoras, tecnol\u00f3gicas, organizacionais e digitais, que promovam o acesso, a qualidade e a efici\u00eancia dos servi\u00e7os de sa\u00fade no munic\u00edpio, observando as boas pr\u00e1ticas de seguran\u00e7a da informa\u00e7\u00e3o e a conformidade com a Lei Geral de Prote\u00e7\u00e3o de Dados (LGPD);</p> </li> <li> <p>a cultura da inova\u00e7\u00e3o e da transforma\u00e7\u00e3o digital no \u00e2mbito da SMS, com a capacita\u00e7\u00e3o dos colaboradores em eventos com a tem\u00e1tica de inova\u00e7\u00e3o;</p> </li> <li> <p>a cultura de governan\u00e7a de dados e articula\u00e7\u00e3o com as subsecretarias da SMS;</p> </li> <li> <p>assessorar tecnicamente os projetos estrat\u00e9gicos da SMS que envolvam tecnologia, inova\u00e7\u00e3o e transforma\u00e7\u00e3o digital, contribuindo para a concep\u00e7\u00e3o e desenvolvimento de sistemas digitais institucionais;</p> </li> <li> <p>propor mecanismos de controle de acesso aos dados geridos, para a prote\u00e7\u00e3o das informa\u00e7\u00f5es nos produtos tecnol\u00f3gicos sob responsabilidade da sua \u00e1rea de atua\u00e7\u00e3o.</p> </li> </ul> </li> </ul>"}]}